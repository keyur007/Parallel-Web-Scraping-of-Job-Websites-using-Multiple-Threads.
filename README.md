# Parallel-Web-Scraping-of-Job-Websites-using-Multiple-Threads.
This project is created with the aim of helping job seekers search for their desired job at their desired location and field of interest and based on their skills.The code used here performs parallel web scrapping of a job website using multiple number of threads generarted by  a web crawler .The results of the search by the user involves creating of a .csv file inluding all the jobs at the desired feild of location and interest based on the comparison of the skill set necessary for the job and the skill set of the seeker.

Abstract:
Web Scrapping is data scraping used for extracting data from the desired or target websites. It is the architecture to access the World Wide Web directly using the HTTP, or through a web browser. The term typically refers to automated processes implemented using a bot or web crawler. It is a form of copying, in which specific data is gathered and copied from the web, typically into a central local database or spreadsheet, for later analysis. Web scraping a web page involves fetching it and extracting from it. Fetching is the downloading of a page. Therefore, web crawling is the main component of web scraping, to fetch pages for later processing. Once fetched, then extraction can take place. The content of a page may be parsed, searched, reformatted and its data copied into a desired format with the help of a crawler that generated multiple threads running throughout the website extracting data in parallel. Web Scrapping of job advertising websites like indeed or monster.com can be used to extract useful information out of the available website contents and links. More over it, company reviews can also be extracted and analyzed for overall evolution of the company availing jobs. Frequency analysis of keywords can be performed on the extracted review data to detect the most frequent used keywords in job summaries as it will be beneficial for job seekers to include those keywords to attract recruiter’s attentions.

INTRODUCTION:
A web data source is a database backed web server which accepts queries in web page forms and returns the set of result items for that query in a web page. Data pre-processing is an often neglected but important step in the data mining process. Pre-processing involves techniques to transform raw data into more understandable format. Data gathered from real world instances is usually incomplete, noisy and inconsistent. Incomplete data lacks attribute values, lacks certain attributes of interest, thereby containing only aggregate module. Noisy data comprises of errors and outliers. Data that is inconsistent contains discrepancies in variables or names. 

Many times data is not easily accessible – although it does exist. As much as one wish that everything will be available in CSV or the format of the one’s choice – most data is published in different forms on the web. There comes the problem that many time, the user want to use the data to combine it with other datasets and explore it independently. One of the solutions is Screen Scraping. Screen Scraping is the technique to capture the data that is being displayed in human readable format on the destination terminal and to replicate it at the source terminal for further processing. Screen scraping is sometimes referred to as terminal emulation. Though there are other ways to get the data out of the web i.e from web-based APIs, such as interfaces provided by online databases, many modern web applications including Twitter, Facebook and many others. This is also a great way to access government or commercial data. Another is to extract data from PDFs as is very difficult. That is why, it is not included in our project scope. The advantage of scraping is that the user can do it with virtually any web site — from weather forecasts to government spending, even if that site does not have an API for raw data access. However, screen scraping is not an independent process. Before scraping the output, Crawlers are responsible to navigate to the destination terminal. The search key entered at the source machine, engages the crawlers to navigate through the links on the web. Once the crawlers successfully reaches the correct page that matches up with the search string, scraping process starts.
